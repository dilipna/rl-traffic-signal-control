<img width="903" height="889" alt="image" src="https://github.com/user-attachments/assets/f3e13df8-64c3-407e-b4bb-c34196314cc5" />

# DilipGPT TrafficRL

Reinforcement Learning-based Traffic Signal Control system using Q-Learning.

This project demonstrates how an RL agent can learn to dynamically control traffic lights at an intersection to reduce congestion compared to a fixed-time baseline controller.

---

## ğŸš€ Live Demo

Interactive UI allows:

- Adjusting traffic arrival rates
- Training the RL agent
- Comparing against baseline strategy
- Viewing training reward curve
- Observing congestion reduction metrics

---

## ğŸ§  Problem Statement

Traditional traffic signals operate on fixed-time schedules, which do not adapt to real-time traffic fluctuations.

This project formulates traffic signal control as a Reinforcement Learning problem where the agent learns to:

- Minimize total queue length
- Adapt signal switching decisions dynamically
- Optimize traffic flow over time

---

## ğŸ—ï¸ Environment Design

### State Representation

State consists of:
- Discretized NS queue length
- Discretized EW queue length
- Current signal phase

Total state space: 5 Ã— 5 Ã— 2

---

### Actions

- 0 â†’ Keep current signal phase
- 1 â†’ Switch signal phase

---

### Reward Function

Reward = âˆ’ (Total Queue Length)

The agent learns to minimize congestion by maximizing cumulative reward.

---

## ğŸ§® Algorithm Used

Q-Learning (Tabular)

Update rule:

Q(s,a) â† Q(s,a) + Î± [ r + Î³ max_a' Q(s',a') âˆ’ Q(s,a) ]

Where:
- Î± = learning rate
- Î³ = discount factor

---

## ğŸ“Š Performance Evaluation

Baseline Controller:
- Fixed-time switching policy

RL Controller:
- Learned switching strategy

Example result:

Baseline avg queue: 73.76  
RL avg queue: 48.69  

The RL policy significantly reduces congestion compared to baseline.

---

## ğŸ“ˆ Visualization

- Training reward per episode
- Before vs After congestion comparison

---

## ğŸ› ï¸ Tech Stack

- Python
- NumPy
- Q-Learning
- Flask (Web UI)
- Matplotlib (Training visualization)
- Cloudflare Tunnel (Temporary public deployment)

---

## ğŸ¯ Key Learning Outcomes

- Designing custom RL environments
- Reward engineering
- State discretization
- Baseline benchmarking
- Policy evaluation
- ML system deployment with UI

---

## ğŸ”® Future Improvements

- Deep Q-Network (DQN)
- Continuous state representation
- Multi-intersection coordination
- Traffic animation visualization
- Real-time streaming simulation

---

## ğŸ‘¨â€ğŸ’» Author

Dilip  
Computer Science student specializing in Artificial Intelligence and Reinforcement Learning.
